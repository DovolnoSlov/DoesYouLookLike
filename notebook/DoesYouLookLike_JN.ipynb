{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93bdcead",
   "metadata": {},
   "source": [
    "# Does You Look Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcd47a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Стас\\\\!Analitic\\\\Start in ML\\\\DoesYouLookLike_JN\\\\model'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.path.join('.', 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8c1da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Главное чтобы все параметры из конфига подтянуть'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from bing_image_downloader.downloader import download\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "''' Главное чтобы все параметры из конфига подтянуть'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21842bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_pics\n",
    "target_actors = ['Angelina Jolie', 'Helena Bonham Carter', 'Jennifer Aniston', 'Julia Roberts', 'Kate Beckinsale',\n",
    "                 'Keira Knightley', 'Lindsey Stirling', 'Marilyn Monroe', 'Monica Bellucci', 'Lucy Liu', 'Scarlett Johansson']\n",
    "\n",
    "path_to_images_dir = os.path.abspath(os.path.join('E:', 'Python', 'BOT', 'image'))\n",
    "path_model = os.path.abspath(os.path.join('E:', 'Python', 'BOT', 'model'))\n",
    "size_new = 256\n",
    "limit_load_image = 15\n",
    "random_state = 13\n",
    "test_size = 0.25\n",
    "coef_C = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8addeb70",
   "metadata": {},
   "source": [
    "1 - download_images (+ rename_dir + count_files_in_dir)\n",
    "\n",
    "2 - reformat_photo\n",
    "\n",
    "3 - GetEmbedding(get_embedding)\n",
    "\n",
    "4 - Загрузка данных + обучение модели + тест модели + сохранение модели в pickle\n",
    "\n",
    "(1-4) выполняются единоразово - для создания обученной модели\n",
    " \n",
    ".\n",
    "\n",
    "5 - Загрузка фото с поиском лица + загрузка модели + предсказание\n",
    "\n",
    "6 - Вывод инфы в бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca79d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(path_download: str, actors: list, limit_load: int=15) -> None:\n",
    "    '''\n",
    "    Загрузка изображений указанных актёров/актрис\n",
    "    \n",
    "    :param path_download: путь для сохранения изображений на сервере\n",
    "    :param actors: список актёров/актрис\n",
    "    :param limit_load: количество изображений для загрузки\n",
    "    \n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    # проверка наличия каталогов с изображениями\n",
    "    # удаление в случае нахождения\n",
    "    try:\n",
    "        shutil.rmtree(path_download)\n",
    "        print('Дерево каталогов удалено')\n",
    "    except OSError as e:\n",
    "        print('Error: %s : %s' % (path_download, e.strerror))\n",
    "\n",
    "    # загрузка изображений из Bing\n",
    "    for name_actor in tqdm(actors):\n",
    "        find_string = f'face {name_actor}'\n",
    "        download(find_string, limit=limit_load,  output_dir=path_download,\n",
    "                 adult_filter_off=True, force_replace=False, timeout=60, verbose=False)\n",
    "        \n",
    "        # переименование каталогов с загруженными изображениями\n",
    "        rename_dir(path_download, find_string, name_actor)\n",
    "        \n",
    "        # подсчёт количества загруженных изображений по каждому запросу\n",
    "        # с удалением при количестве < 2\n",
    "        if count_files_in_dir(path_download, name_actor):\n",
    "            actors.remove(name_actor)\n",
    "\n",
    "        \n",
    "def rename_dir(path_dir: str, name_old: str, name_new: str) -> None:\n",
    "    '''\n",
    "    Переименование каталога\n",
    "    \n",
    "    :param path_dir: путь хранения каталогов\n",
    "    :param name_old: старое имя каталога\n",
    "    :param name_new: новое имя каталога\n",
    "    \n",
    "    :return: None        \n",
    "    '''\n",
    "    \n",
    "    path_old = os.path.join(path_dir, name_old)\n",
    "    path_new = os.path.join(path_dir, name_new)\n",
    "    os.rename(path_old, path_new) \n",
    "\n",
    "    \n",
    "def count_files_in_dir(path_dir: str, name_dir: str) -> bool:\n",
    "    '''\n",
    "    Оценка количества файлов в каталогах\n",
    "    \n",
    "    :param path_dir: путь хранения каталогов\n",
    "    :param name_dir: наименование проверяемого каталога\n",
    "    \n",
    "    :return: True (if < 2) / False\n",
    "    :rtype: bool\n",
    "    '''\n",
    "    \n",
    "    path_listdir = os.path.join(path_dir, name_dir)\n",
    "    files = len(os.listdir(path_listdir))\n",
    "    if files < 2:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48da3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_photo(path_load: str, actors: list, size_new: int) -> None:\n",
    "    '''\n",
    "    Изменение размера всех изображений\n",
    "    :param path_load: путь до каталогов с изображениями\n",
    "    :param actors: список актёров/актрис\n",
    "    :param size_new: необходимый размер изображения по одной из сторон\n",
    "    \n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    for name in actors:\n",
    "        path_to_images = os.path.join(path_load, name)\n",
    "        images = os.listdir(path_to_images)\n",
    "        for img in images:\n",
    "            path_image = os.path.join(path_to_images, img)\n",
    "            # изменение формата изображения и сохранения под тем же именем\n",
    "            with Image.open(path_image) as photo:\n",
    "                photo_resized = resize_photo(photo, size_new)\n",
    "                photo_resized_conv = photo_resized.convert('RGB')\n",
    "                photo_resized_conv.save(path_image)\n",
    "                \n",
    "def resize_photo(image: Image, size_new: int) -> Image:\n",
    "    '''\n",
    "    Изменение размера изображения\n",
    "    :param image: исходное изображение\n",
    "    :param size_new: необходимый размер изображения по одной из сторон\n",
    "    \n",
    "    :return: финальное изображение\n",
    "    :rtype: Image\n",
    "    '''\n",
    "    \n",
    "    # получение размера исходного изображения\n",
    "    size = image.size\n",
    "    \n",
    "    # рассчёт коэффициента по одной из сторон\n",
    "    coef = size_new / size[0]\n",
    "    first_side = int(size[0] * coef)\n",
    "    second_side = int(size[1] * coef)\n",
    "    \n",
    "    # изменение размера изображения\n",
    "    resized_image = image.resize((first_side, second_side))\n",
    "    resized_image = resized_image.convert('RGB')\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c50faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbedding:\n",
    "    '''\n",
    "    Поиск лиц на фотографиях, и сохранение полученных эмбедингов в pickle\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        actors (list): список актёров/актрис \n",
    "        path_load (str): путь до каталогов с изображениями\n",
    "        path_save (str): путь сохранения эмбеддингов и таргетов\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, actors: list, path_load: str, path_save: str):\n",
    "        self.actors = actors\n",
    "        self.path_load = path_load\n",
    "        self.path_save = path_save\n",
    "        \n",
    "    def get_save_embedding(self) -> None:\n",
    "        ''' Получение эмбеддингов, таргетов, имён с индексами, и сохранение в файлы '''\n",
    "        \n",
    "        embeddings, targets, name_labels = self.__create_embedding()\n",
    "        \n",
    "        path_emb = os.path.join(self.path_save, 'embeddings.pkl')\n",
    "        with open(path_emb, 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "        \n",
    "        path_tar = os.path.join(self.path_save, 'targets.pkl')\n",
    "        with open(path_tar, 'wb') as f:\n",
    "            pickle.dump(targets, f)\n",
    "            \n",
    "        path_act = os.path.join(self.path_save, 'name_labels.json')\n",
    "        json_act = json.dumps(name_labels, indent=4)\n",
    "        with open(path_act, 'w') as f:\n",
    "            f.write(json_act)\n",
    "        \n",
    "    def __create_embedding(self) -> tuple[np.array, list, dict]:\n",
    "        '''\n",
    "        Поиск лиц,\n",
    "        и формирование эмбеддингов, таргетов и словаря имена:таргеты\n",
    "\n",
    "        :return: эмбеддинги, таргеты, словарь имена:таргеты\n",
    "        :rtype: tuple[np.array, list, dict]\n",
    "        '''\n",
    "        \n",
    "        embeddings = np.empty(128)\n",
    "        targets = []\n",
    "        name_labels = self.__create_labels()\n",
    "        for name in self.actors:\n",
    "            path_to_images = os.path.join(self.path_load, name)\n",
    "            images_for_name = os.listdir(path_to_images)\n",
    "            for img in images_for_name:\n",
    "                try:\n",
    "                    path_image = os.path.join(path_to_images, img)\n",
    "                    face = face_recognition.load_image_file(path_image)\n",
    "                    \n",
    "                    face_boxes = face_recognition.face_locations(face)\n",
    "                    # если найдено больше 1 лица на изображении - оно исключается\n",
    "                    if len(face_boxes) != 1:\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        face_encod = face_recognition.face_encodings(face)[0]\n",
    "                        embeddings = np.vstack((embeddings, face_encod))\n",
    "                        # добавление таргета по имени\n",
    "                        targets.append(name_labels[name])\n",
    "                    except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "                    \n",
    "                except Exception as ex:\n",
    "                    print(f'Error: {ex}')\n",
    "                    \n",
    "        return embeddings[1:], targets, name_labels\n",
    "                    \n",
    "    def __create_labels(self) -> dict:\n",
    "        ''' Создание словаря имена:таргеты '''\n",
    "        \n",
    "        name_labels = dict()\n",
    "        for label, name in enumerate(self.actors):\n",
    "            name_labels[name] = label\n",
    "        return name_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d249cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! Универсальность функции по доставанию лица с изображения\n",
    "# чтобы использовать для соло фотографии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eb86dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' С проверкой на необходимость закачки и предобработки данных! '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelImgLR:\n",
    "    '''\n",
    "    Модель логистической регрессии\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        path_load (str): путь до каталога с эмбеддингами и таргетами\n",
    "        random_state (int): параметр random_state\n",
    "        test_size (float): параметр test_size для train_test_split\n",
    "        coef_C (float): параметр C для логистической регрессии\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path_load:str, random_state: int=0, test_size: float=0.3, coef_C: float = 1.0):\n",
    "        self.path_load = path_load\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.coef_C = coef_C\n",
    "        \n",
    "        # загрузка эмбеддингов и таргетов\n",
    "        self.embeddings, self.targets = self.__load_data()\n",
    "\n",
    "    def fit_model(self) -> LogisticRegression:\n",
    "        ''' \n",
    "        Обучение модели, \n",
    "        сохранение в pickle, в каталог с эмбеддингами и таргетами\n",
    "\n",
    "        :return: модель машинного обучения, тестовые данные X_test и y_test\n",
    "        :rtype: LogisticRegression, np.array, np.array\n",
    "\n",
    "        '''\n",
    "        \n",
    "        min_num_target, name_min_target = self.__check_min_target()\n",
    "        if min_num_target > 1:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.embeddings, self.targets, \n",
    "                                                                test_size=self.test_size, \n",
    "                                                                random_state=self.random_state,\n",
    "                                                                stratify=self.targets)\n",
    "            model_LR = LogisticRegression(random_state=self.random_state, C = self.coef_C)\n",
    "            model_LR.fit(X_train, y_train)\n",
    "            \n",
    "            self.__save_model(model_LR)\n",
    "            \n",
    "            return model_LR, X_test, y_test\n",
    "        else:\n",
    "            #logging.info(f'Problem with data. Target: {name_min_target}')\n",
    "            print(f'Problem with data. Target: {name_min_target}')\n",
    "    \n",
    "    def __load_data(self) -> tuple[np.array, list]:\n",
    "        ''' Загрузка данных для обучения '''\n",
    "        \n",
    "        try:\n",
    "            path_embeddings = os.path.join(self.path_load, 'embeddings.pkl')\n",
    "            with open(path_embeddings, 'rb') as file:\n",
    "                load_embeddings = pickle.load(file)\n",
    "\n",
    "            path_targets = os.path.join(self.path_load, 'targets.pkl')\n",
    "            with open(path_targets, 'rb') as file:\n",
    "                load_targets = pickle.load(file)\n",
    "        except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "        else:\n",
    "            return load_embeddings, load_targets\n",
    "        \n",
    "    def __check_min_target(self) -> tuple[int, str]:\n",
    "        ''' Подсчёт количества каждой из меток в списке, с нахождением минимального '''\n",
    "\n",
    "        targets_counter = Counter(self.targets)\n",
    "        min_num_target = np.inf\n",
    "        name_min_target = ''\n",
    "        for target in targets_counter.keys():\n",
    "            if targets_counter[target] < min_num_target:\n",
    "                min_num_target = targets_counter[target]\n",
    "                name_min_target = target\n",
    "\n",
    "        return min_num_target, str(name_min_target)\n",
    "    \n",
    "    def __save_model(self, model_LR: LogisticRegression) -> None:\n",
    "        ''' Сохранение модели логистической регрессии в файл '''\n",
    "        \n",
    "        path_save = os.path.join(self.path_load, 'model_LR.pkl')\n",
    "        with open(path_save, 'wb') as f:\n",
    "            pickle.dump(model_LR, f)\n",
    "        \n",
    "\n",
    "    # ну и запуск всего добра\n",
    "    #__name__ == __main__:\n",
    "''' запуск всего скрипта на обучение, файлы до этого не запускаются сами '''\n",
    "''' С проверкой на необходимость закачки и предобработки данных! '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6268df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дерево каталогов удалено\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Angelina Jolie\n",
      "[!] Issue getting: https://s.yimg.com/ny/api/res/1.2/IxNuyItRgvBgVSspytvmOg--~A/YXBwaWQ9aGlnaGxhbmRlcjtzbT0xO3c9ODAw/http://media.zenfs.com/en-US/homerun/hello_giggles_454/6b982e94b82db4201dce770c9fe6592f\n",
      "[!] Error:: HTTP Error 401: Unauthorized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▌                                                                           | 1/11 [00:17<02:52, 17.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Helena Bonham Carter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|███████████████                                                                    | 2/11 [00:26<01:54, 12.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Jennifer Aniston\n",
      "[Error]Invalid image, not saving http://images3.wikia.nocookie.net/__cb20120521155228/doblajesanimados/es/images/f/f9/Jennifer_Aniston.jpg\n",
      "\n",
      "[!] Issue getting: http://images3.wikia.nocookie.net/__cb20120521155228/doblajesanimados/es/images/f/f9/Jennifer_Aniston.jpg\n",
      "[!] Error:: Invalid image, not saving http://images3.wikia.nocookie.net/__cb20120521155228/doblajesanimados/es/images/f/f9/Jennifer_Aniston.jpg\n",
      "\n",
      "[!] Issue getting: https://www.myconfinedspace.com/wp-content/uploads/tdomf/136776/JenniferAnistonIndeximage.jpg\n",
      "[!] Error:: <urlopen error [WinError 10060] Попытка установить соединение была безуспешной, т.к. от другого компьютера за требуемое время не получен нужный отклик, или было разорвано уже установленное соединение из-за неверного отклика уже подключенного компьютера>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████████▋                                                            | 3/11 [01:01<03:02, 22.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Julia Roberts\n",
      "[!] Issue getting: https://celebsheight.org/actors/8-Julia Roberts.jpg\n",
      "[!] Error:: URL can't contain control characters. '/actors/8-Julia Roberts.jpg' (found at least ' ')\n",
      "[!] Issue getting: https://i1.wp.com/incosmetics.wordpress.com/files/2009/12/julia-roberts-lancome1.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n",
      "[!] Issue getting: http://www.hdnicewallpapers.com/Walls/Big/Julia Roberts/Beautiful_Face_of_Julia_Roberts.jpg\n",
      "[!] Error:: URL can't contain control characters. '/Walls/Big/Julia Roberts/Beautiful_Face_of_Julia_Roberts.jpg' (found at least ' ')\n",
      "[!] Issue getting: https://www.hdnicewallpapers.com/Walls/Big/Julia Roberts/Beautiful_Face_Julia_Roberts.jpg\n",
      "[!] Error:: URL can't contain control characters. '/Walls/Big/Julia Roberts/Beautiful_Face_Julia_Roberts.jpg' (found at least ' ')\n",
      "[Error]Invalid image, not saving https://i.dailymail.co.uk/i/pix/2013/10/23/article-0-18E2418300000578-74_638x905.jpg\n",
      "\n",
      "[!] Issue getting: https://i.dailymail.co.uk/i/pix/2013/10/23/article-0-18E2418300000578-74_638x905.jpg\n",
      "[!] Error:: Invalid image, not saving https://i.dailymail.co.uk/i/pix/2013/10/23/article-0-18E2418300000578-74_638x905.jpg\n",
      "\n",
      "[!] Issue getting: https://images6.alphacoders.com/775/775154.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|██████████████████████████████▏                                                    | 4/11 [01:25<02:42, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Kate Beckinsale\n",
      "[Error]Invalid image, not saving http://www.vidigy.com/wp-content/uploads/2012/04/Kate-Beckinsale_0412-1.jpg\n",
      "\n",
      "[!] Issue getting: http://www.vidigy.com/wp-content/uploads/2012/04/Kate-Beckinsale_0412-1.jpg\n",
      "[!] Error:: Invalid image, not saving http://www.vidigy.com/wp-content/uploads/2012/04/Kate-Beckinsale_0412-1.jpg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|█████████████████████████████████████▋                                             | 5/11 [01:41<02:04, 20.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Keira Knightley\n",
      "[!] Issue getting: https://external-preview.redd.it/4EkLDTKR_tQ1P9fy_5dwnpjlh0_maITfIugSD7O2laM.jpg?auto=webp&amp;s=83d773e9e9753f6d15df103e072b20029a053eef\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: https://static3.businessinsider.com/image/5ab95d6442e1cc20fa25a8b6-2005/keira knightley attends the atonement photocall during day 1 of the 64th annual venice film festival on august 29 2007 in venice italy.jpg\n",
      "[!] Error:: URL can't contain control characters. '/image/5ab95d6442e1cc20fa25a8b6-2005/keira knightley attends the atonement photocall during day 1 of the 64th annual venice film festival on august 29 2007 in venice italy.jpg' (found at least ' ')\n",
      "[Error]Invalid image, not saving http://sizzlingsuperstars.com/wp-content/uploads/2016/07/Keira-Knightley-10.jpg\n",
      "\n",
      "[!] Issue getting: http://sizzlingsuperstars.com/wp-content/uploads/2016/07/Keira-Knightley-10.jpg\n",
      "[!] Error:: Invalid image, not saving http://sizzlingsuperstars.com/wp-content/uploads/2016/07/Keira-Knightley-10.jpg\n",
      "\n",
      "[!] Issue getting: https://image.tmdb.org/t/p/original/8GaYprIb8GlljllLnZtQyIZ7thU.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: http://celeb-face.com/albums/celebrities/u/11/Keira-Knightley/Keira-Knightley-2021.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████████▎                                     | 6/11 [01:52<01:27, 17.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Lindsey Stirling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████████▊                              | 7/11 [02:11<01:11, 17.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Marilyn Monroe\n",
      "[!] Issue getting: http://www.celeb-face.com/albums/celebrities/u/9/Marilyn-Monroe/Marilyn-Monroe-479.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n",
      "[!] Issue getting: https://i1.wp.com/fronkonstin.com/wp-content/uploads/2014/02/marilyn-monroe3.jpg\n",
      "[!] Error:: HTTP Error 404: Not Found\n",
      "[Error]Invalid image, not saving http://i.dailymail.co.uk/i/pix/2015/01/05/007498A200000258-0-image-a-40_1420436941542.jpg\n",
      "\n",
      "[!] Issue getting: http://i.dailymail.co.uk/i/pix/2015/01/05/007498A200000258-0-image-a-40_1420436941542.jpg\n",
      "[!] Error:: Invalid image, not saving http://i.dailymail.co.uk/i/pix/2015/01/05/007498A200000258-0-image-a-40_1420436941542.jpg\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████████████▎                      | 8/11 [02:28<00:53, 17.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Monica Bellucci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|███████████████████████████████████████████████████████████████████▉               | 9/11 [02:38<00:30, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Lucy Liu\n",
      "[!] Issue getting: https://image.tmdb.org/t/p/original/1leItxMN9yxvySPNpJJqQFUFUT9.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: http://image.tmdb.org/t/p/original/dW6JDvYhXWW87P04W2SfNpiAwCO.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: http://media1.popsugar-assets.com/files/2012/11/45/5/192/1922153/7bd9dbc672fa0f19_155854280/i/Lucy-Liu.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: http://www.graphis.com/media/uploads/cfe/entry/ab5a6d12-08a3-4334-8b1f-d3d2542aa305/120116_LATIMES_LUCY-Liu164.jpg\n",
      "[!] Error:: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1129)>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|██████████████████████████████████████████████████████████████████████████▌       | 10/11 [02:50<00:14, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n",
      "[%] Downloading Images to E:\\Python\\BOT\\image\\face Scarlett Johansson\n",
      "[!] Issue getting: https://cdn.wallpapersafari.com/44/57/proNjB.jpg\n",
      "[!] Error:: <urlopen error [Errno 2] No such file or directory>\n",
      "[!] Issue getting: https://images6.alphacoders.com/405/thumb-1920-405788.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n",
      "[!] Issue getting: https://images7.alphacoders.com/362/362419.jpg\n",
      "[!] Error:: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [03:08<00:00, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[%] Done. Downloaded 15 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download_images(path_to_images_dir, target_actors, limit_load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abee0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat_photo(path_to_images_dir, target_actors, size_new)\n",
    "# actors_embedding = GetEmbedding(target_actors, path_to_images_dir, path_model)\n",
    "# actors_embedding.get_save_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7cc48563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#MyModel = ModelImgLR(path_model, random_state, test_size, coef_C)\n",
    "MyModel = ModelImgLR(path_model, random_state, test_size)\n",
    "model_LR, X_test, y_test = MyModel.fit_model()\n",
    "f1_model_score = f1_score(y_test, model_LR.predict(X_test), average='micro')\n",
    "print(f'F1 score: {f1_model_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "db5af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictModelImgLR:\n",
    "    '''\n",
    "    Предсказание на модели логистической регрессии по тестовому изображению\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        path_load (str): путь до каталога с тестовым изображением\n",
    "        size_new (int): необходимый размер изображения по одной из сторон\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path_load:str, size_new:int):\n",
    "        self.path_load = path_load\n",
    "        self.size_new = size_new\n",
    "        \n",
    "        # загрузка модели, словаря имён:таргетов\n",
    "        self.model, self.name_labels = self.__load_data()\n",
    "\n",
    "    def predict_model(self) -> None:\n",
    "        ''' Предсказание на модели логистической регрессии '''\n",
    "        \n",
    "        test_photo_resized_conv = self.__load_image()\n",
    "        \n",
    "        test_face_boxes = face_recognition.face_locations(test_photo_resized_conv)\n",
    "        # если найдено больше 1 лица на изображении - оно исключается\n",
    "        if len(test_face_boxes) == 1:\n",
    "            test_face_encod = face_recognition.face_encodings(test_photo_resized_conv)[0]\n",
    "            test_predict = self.model.predict([test_face_encod])\n",
    "            test_predict_name = list(self.name_labels.keys())[list(self.name_labels.values()).index(test_predict)]\n",
    "            print('predict: %d' % test_predict)\n",
    "            print('predict name: %s' % test_predict_name)\n",
    "            \n",
    "            \n",
    "            test_predict_proba = self.model.predict_proba([test_face_encod])[0][test_predict][0]\n",
    "            print(test_predict_proba)\n",
    "            \n",
    "    \n",
    "    def __load_data(self) -> tuple[np.array, dict]:\n",
    "        ''' Загрузка данных для обучения '''\n",
    "        \n",
    "        try:\n",
    "            path_model = os.path.join(self.path_load, 'model_LR.pkl')\n",
    "            with open(path_model, 'rb') as file:\n",
    "                load_model = pickle.load(file)\n",
    "\n",
    "            path_act = os.path.join(self.path_load, 'name_labels.json')\n",
    "            with open(path_act, 'r') as file:\n",
    "                load_name_labels = json.load(file)\n",
    "        except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "        else:\n",
    "            return load_model, load_name_labels\n",
    "        \n",
    "    def __load_image(self) -> np.array(Image):\n",
    "        ''' Загрузка изображения, с изменением размера '''\n",
    "        \n",
    "        path_test_image = os.path.join(self.path_load, 'test_image.jpg')\n",
    "        # изменение формата тестового изображения\n",
    "        with Image.open(path_test_image) as photo:\n",
    "            test_photo_resized = resize_photo(photo, self.size_new)\n",
    "            test_photo_resized_conv = np.array(test_photo_resized.convert('RGB'))\n",
    "        \n",
    "        return test_photo_resized_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd49b34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 1\n",
      "predict name: Helena Bonham Carter\n",
      "0.1387612180102584\n"
     ]
    }
   ],
   "source": [
    "predict_model_img_lr = PredictModelImgLR(path_model, size_new)\n",
    "predict_model_img_lr.predict_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69140134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " col1  col2\n",
      "    1     4\n",
      "    2     5\n"
     ]
    }
   ],
   "source": [
    "d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
    "df = pd.DataFrame(d)\n",
    "print(df[:2].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
