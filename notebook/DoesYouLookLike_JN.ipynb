{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93bdcead",
   "metadata": {},
   "source": [
    "# Does You Look Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f922e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Стас\\\\!Analitic\\\\Start in ML\\\\DoesYouLookLike_JN\\\\model'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(os.path.join('.', 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8c1da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Главное чтобы все параметры из конфига подтянуть'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from bing_image_downloader.downloader import download\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "import multiprocessing\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "''' Главное чтобы все параметры из конфига подтянуть'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21842bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_pics\n",
    "target_actors = ['Angelina Jolie', 'Helena Bonham Carter', 'Jennifer Aniston', 'Julia Roberts', 'Kate Beckinsale',\n",
    "                 'Keira Knightley', 'Lindsey Stirling', 'Marilyn Monroe', 'Monica Bellucci', 'Lucy Liu', 'Scarlett Johansson']\n",
    "\n",
    "path_to_images_dir = os.path.abspath(os.path.join('E:', 'Python', 'BOT', 'image'))\n",
    "path_model = os.path.abspath(os.path.join('E:', 'Python', 'BOT', 'model'))\n",
    "size_image_new = 256\n",
    "size_image_test = 512\n",
    "limit_load_image = 15\n",
    "random_state = 13\n",
    "test_size = 0.25\n",
    "coef_C = 0.8\n",
    "n_splits = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8addeb70",
   "metadata": {},
   "source": [
    "1 - download_images (+ rename_dir + count_files_in_dir)\n",
    "\n",
    "2 - reformat_photo\n",
    "\n",
    "3 - GetEmbedding(get_embedding)\n",
    "\n",
    "4 - Загрузка данных + обучение модели + тест модели + сохранение модели в pickle\n",
    "\n",
    "(1-4) выполняются единоразово - для создания обученной модели\n",
    " \n",
    ".\n",
    "\n",
    "5 - Загрузка фото с поиском лица + загрузка модели + предсказание\n",
    "\n",
    "6 - Вывод инфы в бота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca79d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(path_download: str, actors: list, limit_load: int=15) -> None:\n",
    "    '''\n",
    "    Загрузка изображений указанных актёров/актрис\n",
    "    \n",
    "    :param path_download: путь для сохранения изображений на сервере\n",
    "    :param actors: список актёров/актрис\n",
    "    :param limit_load: количество изображений для загрузки\n",
    "    \n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    # проверка наличия каталогов с изображениями\n",
    "    # удаление в случае нахождения\n",
    "    try:\n",
    "        shutil.rmtree(path_download)\n",
    "        print('Дерево каталогов удалено')\n",
    "    except OSError as e:\n",
    "        print('Error: %s : %s' % (path_download, e.strerror))\n",
    "\n",
    "    # загрузка изображений из Bing\n",
    "    for name_actor in tqdm(actors):\n",
    "        find_string = f'face {name_actor}'\n",
    "        download(find_string, limit=limit_load,  output_dir=path_download,\n",
    "                 adult_filter_off=True, force_replace=False, timeout=60, verbose=False)\n",
    "        \n",
    "        # переименование каталогов с загруженными изображениями\n",
    "        rename_dir(path_download, find_string, name_actor)\n",
    "        \n",
    "        # подсчёт количества загруженных изображений по каждому запросу\n",
    "        # с удалением при количестве < 2\n",
    "        if count_files_in_dir(path_download, name_actor):\n",
    "            actors.remove(name_actor)\n",
    "\n",
    "        \n",
    "def rename_dir(path_dir: str, name_old: str, name_new: str) -> None:\n",
    "    '''\n",
    "    Переименование каталога\n",
    "    \n",
    "    :param path_dir: путь хранения каталогов\n",
    "    :param name_old: старое имя каталога\n",
    "    :param name_new: новое имя каталога\n",
    "    \n",
    "    :return: None        \n",
    "    '''\n",
    "    \n",
    "    path_old = os.path.join(path_dir, name_old)\n",
    "    path_new = os.path.join(path_dir, name_new)\n",
    "    os.rename(path_old, path_new) \n",
    "\n",
    "    \n",
    "def count_files_in_dir(path_dir: str, name_dir: str) -> bool:\n",
    "    '''\n",
    "    Оценка количества файлов в каталогах\n",
    "    \n",
    "    :param path_dir: путь хранения каталогов\n",
    "    :param name_dir: наименование проверяемого каталога\n",
    "    \n",
    "    :return: True (if < 2) / False\n",
    "    :rtype: bool\n",
    "    '''\n",
    "    \n",
    "    path_listdir = os.path.join(path_dir, name_dir)\n",
    "    files = len(os.listdir(path_listdir))\n",
    "    if files < 2:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48da3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_photo(path_load: str, actors: list, size_new: int) -> None:\n",
    "    '''\n",
    "    Изменение размера всех изображений\n",
    "    :param path_load: путь до каталогов с изображениями\n",
    "    :param actors: список актёров/актрис\n",
    "    :param size_new: необходимый размер изображения по одной из сторон\n",
    "    \n",
    "    :return: None\n",
    "    '''\n",
    "    \n",
    "    for name in actors:\n",
    "        path_to_images = os.path.join(path_load, name)\n",
    "        images = os.listdir(path_to_images)\n",
    "        for img in images:\n",
    "            path_image = os.path.join(path_to_images, img)\n",
    "            # изменение формата изображения и сохранения под тем же именем\n",
    "            with Image.open(path_image) as photo:\n",
    "                photo_resized = resize_photo(photo, size_new)\n",
    "                photo_resized_conv = photo_resized.convert('RGB')\n",
    "                photo_resized_conv.save(path_image)\n",
    "                \n",
    "def resize_photo(image: Image, size_new: int) -> Image:\n",
    "    '''\n",
    "    Изменение размера изображения\n",
    "    :param image: исходное изображение\n",
    "    :param size_new: необходимый размер изображения по одной из сторон\n",
    "    \n",
    "    :return: финальное изображение\n",
    "    :rtype: Image\n",
    "    '''\n",
    "    \n",
    "    # получение размера исходного изображения\n",
    "    size = image.size\n",
    "    \n",
    "    # рассчёт коэффициента по одной из сторон\n",
    "    coef = size_new / size[0]\n",
    "    first_side = int(size[0] * coef)\n",
    "    second_side = int(size[1] * coef)\n",
    "    \n",
    "    # изменение размера изображения\n",
    "    resized_image = image.resize((first_side, second_side))\n",
    "    resized_image = resized_image.convert('RGB')\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65c50faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEmbedding:\n",
    "    '''\n",
    "    Поиск лиц на фотографиях, и сохранение полученных эмбедингов в pickle\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        actors (list): список актёров/актрис \n",
    "        path_load (str): путь до каталогов с изображениями\n",
    "        path_save (str): путь сохранения эмбеддингов и таргетов\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, actors: list, path_load: str, path_save: str):\n",
    "        self.actors = actors\n",
    "        self.path_load = path_load\n",
    "        self.path_save = path_save\n",
    "        \n",
    "    def get_save_embedding(self) -> None:\n",
    "        ''' Получение эмбеддингов, таргетов, имён с индексами, и сохранение в файлы '''\n",
    "        \n",
    "        embeddings, targets, name_labels = self.__create_embedding()\n",
    "        \n",
    "        path_emb = os.path.join(self.path_save, 'embeddings.pkl')\n",
    "        with open(path_emb, 'wb') as f:\n",
    "            pickle.dump(embeddings, f)\n",
    "        \n",
    "        path_tar = os.path.join(self.path_save, 'targets.pkl')\n",
    "        with open(path_tar, 'wb') as f:\n",
    "            pickle.dump(targets, f)\n",
    "            \n",
    "        path_act = os.path.join(self.path_save, 'name_labels.json')\n",
    "        json_act = json.dumps(name_labels, indent=4)\n",
    "        with open(path_act, 'w') as f:\n",
    "            f.write(json_act)\n",
    "        \n",
    "    def __create_embedding(self) -> tuple[np.array, list, dict]:\n",
    "        '''\n",
    "        Поиск лиц,\n",
    "        и формирование эмбеддингов, таргетов и словаря имена:таргеты\n",
    "\n",
    "        :return: эмбеддинги, таргеты, словарь имена:таргеты\n",
    "        :rtype: tuple[np.array, list, dict]\n",
    "        '''\n",
    "        \n",
    "        embeddings = np.empty(128)\n",
    "        targets = []\n",
    "        name_labels = self.__create_labels()\n",
    "        for name in self.actors:\n",
    "            path_to_images = os.path.join(self.path_load, name)\n",
    "            images_for_name = os.listdir(path_to_images)\n",
    "            for img in images_for_name:\n",
    "                try:\n",
    "                    path_image = os.path.join(path_to_images, img)\n",
    "                    face = face_recognition.load_image_file(path_image)\n",
    "                    \n",
    "                    face_boxes = face_recognition.face_locations(face)\n",
    "                    # если найдено больше 1 лица на изображении - оно исключается\n",
    "                    if len(face_boxes) != 1:\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        face_encod = face_recognition.face_encodings(face)[0]\n",
    "                        embeddings = np.vstack((embeddings, face_encod))\n",
    "                        # добавление таргета по имени\n",
    "                        targets.append(name_labels[name])\n",
    "                    except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "                    \n",
    "                except Exception as ex:\n",
    "                    print(f'Error: {ex}')\n",
    "                    \n",
    "        return embeddings[1:], targets, name_labels\n",
    "                    \n",
    "    def __create_labels(self) -> dict:\n",
    "        ''' Создание словаря имена:таргеты '''\n",
    "        \n",
    "        name_labels = dict()\n",
    "        for label, name in enumerate(self.actors):\n",
    "            name_labels[name] = label\n",
    "        return name_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618baf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вторая версия (с Кросс-валидацией) даёт результат хуже\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1eb86dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' С проверкой на необходимость закачки и предобработки данных! '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ModelImgLR:\n",
    "    '''\n",
    "    Модель логистической регрессии\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        path_load (str): путь до каталога с эмбеддингами и таргетами\n",
    "        random_state (int): параметр random_state\n",
    "        test_size (float): параметр test_size для train_test_split\n",
    "        coef_C (float): параметр C для логистической регрессии\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path_load:str, random_state: int=0, test_size: float=0.3, n_splits: int=5, coef_C: float = 1.0):\n",
    "        self.path_load = path_load\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.coef_C = coef_C\n",
    "        #self.skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "        \n",
    "        # загрузка эмбеддингов и таргетов\n",
    "        self.embeddings, self.targets = self.__load_data()\n",
    "\n",
    "    def fit_model(self) -> LogisticRegression:\n",
    "        ''' \n",
    "        Обучение модели, \n",
    "        сохранение в pickle, в каталог с эмбеддингами и таргетами\n",
    "\n",
    "        :return: модель машинного обучения, тестовые данные X_test и y_test\n",
    "        :rtype: LogisticRegression, np.array, np.array\n",
    "\n",
    "        '''\n",
    "        \n",
    "        min_num_target, name_min_target = self.__check_min_target()\n",
    "        if min_num_target > 1:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(self.embeddings, self.targets, \n",
    "                                                                test_size=self.test_size, \n",
    "                                                                random_state=self.random_state,\n",
    "                                                                stratify=self.targets)\n",
    "            \n",
    "            #log_values = np.logspace(-1, 10, 500)\n",
    "            #model_LR = LogisticRegressionCV(cv=self.skf, Cs=log_values, random_state=self.random_state, solver='newton-cg')\n",
    "            model_LR = LogisticRegression(random_state=self.random_state, C = self.coef_C)\n",
    "            model_LR.fit(X_train, y_train)\n",
    "            \n",
    "            self.__save_model(model_LR)\n",
    "            \n",
    "            return model_LR, X_test, y_test\n",
    "        else:\n",
    "            #logging.info(f'Problem with data. Target: {name_min_target}')\n",
    "            print(f'Problem with data. Target: {name_min_target}')\n",
    "    \n",
    "    def __load_data(self) -> tuple[np.array, list]:\n",
    "        ''' Загрузка данных для обучения '''\n",
    "        \n",
    "        try:\n",
    "            path_embeddings = os.path.join(self.path_load, 'embeddings.pkl')\n",
    "            with open(path_embeddings, 'rb') as file:\n",
    "                load_embeddings = pickle.load(file)\n",
    "\n",
    "            path_targets = os.path.join(self.path_load, 'targets.pkl')\n",
    "            with open(path_targets, 'rb') as file:\n",
    "                load_targets = pickle.load(file)\n",
    "        except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "        else:\n",
    "            return load_embeddings, load_targets\n",
    "        \n",
    "    def __check_min_target(self) -> tuple[int, str]:\n",
    "        ''' Подсчёт количества каждой из меток в списке, с нахождением минимального '''\n",
    "\n",
    "        targets_counter = Counter(self.targets)\n",
    "        min_num_target = np.inf\n",
    "        name_min_target = ''\n",
    "        for target in targets_counter.keys():\n",
    "            if targets_counter[target] < min_num_target:\n",
    "                min_num_target = targets_counter[target]\n",
    "                name_min_target = target\n",
    "\n",
    "        return min_num_target, str(name_min_target)\n",
    "    \n",
    "    def __save_model(self, model_LR: LogisticRegression) -> None:\n",
    "        ''' Сохранение модели логистической регрессии в файл '''\n",
    "        \n",
    "        path_save = os.path.join(self.path_load, 'model_LR.pkl')\n",
    "        with open(path_save, 'wb') as f:\n",
    "            pickle.dump(model_LR, f)\n",
    "        \n",
    "\n",
    "    # ну и запуск всего добра\n",
    "    #__name__ == __main__:\n",
    "''' запуск всего скрипта на обучение, файлы до этого не запускаются сами '''\n",
    "''' С проверкой на необходимость закачки и предобработки данных! '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6268df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_images(path_to_images_dir, target_actors, limit_load_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abee0aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat_photo(path_to_images_dir, target_actors, size_image_new)\n",
    "# actors_embedding = GetEmbedding(target_actors, path_to_images_dir, path_model)\n",
    "# actors_embedding.get_save_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cc48563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#MyModel = ModelImgLR(path_model, random_state, test_size, coef_C)\n",
    "MyModel = ModelImgLR(path_model, random_state, test_size, n_splits)\n",
    "model_LR, X_test, y_test = MyModel.fit_model()\n",
    "f1_model_score = f1_score(y_test, model_LR.predict(X_test), average='micro')\n",
    "print(f'F1 score: {f1_model_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db5af7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictModelImgLR:\n",
    "    '''\n",
    "    Предсказание на модели логистической регрессии по тестовому изображению\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        path_load (str): путь до каталога с тестовым изображением\n",
    "        size_new (int): необходимый размер изображения по одной из сторон\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, path_load:str, size_new:int):\n",
    "        self.path_load = path_load\n",
    "        self.size_new = size_new\n",
    "        \n",
    "        # загрузка модели, словаря имён:таргетов\n",
    "        self.model, self.name_labels = self.__load_data()\n",
    "\n",
    "    def predict_model(self) -> None:\n",
    "        ''' Предсказание на модели логистической регрессии '''\n",
    "        \n",
    "        test_photo_resized_conv = self.__load_image()\n",
    "        \n",
    "        test_face_boxes = face_recognition.face_locations(test_photo_resized_conv)\n",
    "        # если найдено больше 1 лица на изображении - оно исключается\n",
    "        if len(test_face_boxes) == 1:\n",
    "            test_face_encod = face_recognition.face_encodings(test_photo_resized_conv)[0]\n",
    "            test_predict = self.model.predict([test_face_encod])\n",
    "            test_predict_name = list(self.name_labels.keys())[list(self.name_labels.values()).index(test_predict)]\n",
    "            print('predict: %d' % test_predict)\n",
    "            print('predict name: %s' % test_predict_name)\n",
    "            \n",
    "            \n",
    "            test_predict_proba = self.model.predict_proba([test_face_encod])[0][test_predict][0]\n",
    "            print(test_predict_proba)\n",
    "            \n",
    "    \n",
    "    def __load_data(self) -> tuple[np.array, dict]:\n",
    "        ''' Загрузка данных для обучения '''\n",
    "        \n",
    "        try:\n",
    "            path_model = os.path.join(self.path_load, 'model_LR.pkl')\n",
    "            with open(path_model, 'rb') as file:\n",
    "                load_model = pickle.load(file)\n",
    "\n",
    "            path_act = os.path.join(self.path_load, 'name_labels.json')\n",
    "            with open(path_act, 'r') as file:\n",
    "                load_name_labels = json.load(file)\n",
    "        except Exception as ex:\n",
    "                        print(f'Error: {ex}')\n",
    "        else:\n",
    "            return load_model, load_name_labels\n",
    "        \n",
    "    def __load_image(self) -> np.array(Image):\n",
    "        ''' Загрузка изображения, с изменением размера '''\n",
    "        \n",
    "        path_test_image = os.path.join(self.path_load, 'test_image4.jpg')\n",
    "        # изменение формата тестового изображения\n",
    "        with Image.open(path_test_image) as photo:\n",
    "            test_photo_resized = resize_photo(photo, self.size_new)\n",
    "            test_photo_resized_conv = np.array(test_photo_resized.convert('RGB'))\n",
    "        \n",
    "        return test_photo_resized_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4759f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: 8\n",
      "predict name: Monica Bellucci\n",
      "0.22477677580364722\n"
     ]
    }
   ],
   "source": [
    "predict_model_img_lr = PredictModelImgLR(path_model, size_image_test)\n",
    "predict_model_img_lr.predict_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2694680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13193c02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "12ce151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " col1  col2\n",
      "    1     4\n",
      "    2     5\n"
     ]
    }
   ],
   "source": [
    "d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\n",
    "df = pd.DataFrame(d)\n",
    "print(df[:2].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c205890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5caa3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([1.00000000e-01, 1.05206867e-01, 1.10684849e-01, 1.16448062e-01,\n",
       "       1.22511358e-01, 1.28890361e-01, 1.35601511e-01, 1.42662102e-01,\n",
       "       1.50090328e-01, 1.57905331e-01, 1.66127252e-01, 1.74777277e-01,\n",
       "       1.83877698e-01, 1.93451965e-01, 2.03524752e-01, 2.14122015e-01,\n",
       "       2.25271064e-01, 2.37000629e-01, 2.49340937e-01, 2.62323788e-01,\n",
       "       2.75982639e-01, 2.90...\n",
       "       3.81208280e+09, 4.01057288e+09, 4.21939808e+09, 4.43909653e+09,\n",
       "       4.67023439e+09, 4.91340729e+09, 5.16924187e+09, 5.43839743e+09,\n",
       "       5.72156756e+09, 6.01948197e+09, 6.33290840e+09, 6.66265452e+09,\n",
       "       7.00957009e+09, 7.37454909e+09, 7.75853206e+09, 8.16250851e+09,\n",
       "       8.58751948e+09, 9.03466021e+09, 9.50508296e+09, 1.00000000e+10]),\n",
       "                     cv=StratifiedKFold(n_splits=3, random_state=13, shuffle=True),\n",
       "                     random_state=13, solver='newton-cg')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_model_tmp = os.path.join(path_model, 'model_LR.pkl')\n",
    "with open(path_model_tmp, 'rb') as file:\n",
    "    load_model_tmp = pickle.load(file)\n",
    "load_model_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4cb824",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
